{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c910fbf",
   "metadata": {},
   "source": [
    "# Text Classification Notebook\n",
    "This notebook reproduces the workflow in the project's `app.py` and `src/TextClassifier.py`.\n",
    "Each logical step from data loading to training, evaluation and prediction is provided in its own cell with a short explanation.\n",
    "Run the cells in order to reproduce the .py behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b166e",
   "metadata": {},
   "source": [
    "## 1) Imports and logging\n",
    "We import the same libraries used by the scripts and set up basic logging for visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5bc7a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 13:28:15,594 - INFO - Imports complete.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logging.info(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd1ed2",
   "metadata": {},
   "source": [
    "## 2) TextClassifier class\n",
    "Copying the `TextClassifier` implementation from `src/TextClassifier.py` so the notebook is standalone.\n",
    "The class includes preprocessing, training, prediction and evaluation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722dce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier:\n",
    "    \"\"\"\n",
    "    A simple text classification pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "        logging.info(\"TextClassifier initialized.\")\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Cleans and normalizes a single text string.\n",
    "        - Lowercases text\n",
    "        - Removes non-alphanumeric characters (keeping spaces)\n",
    "        \"\"\"\n",
    "        logging.debug(f\"Preprocessing text: '{text}'\")\n",
    "        text = text.lower()\n",
    "        non_alphabetical_characters = r\"[^a-z\\s]\"\n",
    "        text = re.sub(non_alphabetical_characters, \"\", text)\n",
    "        text = \" \".join(text.split())\n",
    "        logging.debug(f\"Preprocessed text: '{text}'\")\n",
    "        return text\n",
    "\n",
    "    def train(self, texts: list[str], labels: list[str]):\n",
    "        \"\"\"\n",
    "        Trains the classification model.\n",
    "        \"\"\"\n",
    "        logging.info(\"Starting model training.\")\n",
    "        # Preprocess all texts\n",
    "        processed_texts = [self.preprocess_text(text) for text in texts]\n",
    "\n",
    "        # Fit vectorizer and transform texts\n",
    "        X = self.vectorizer.fit_transform(processed_texts)\n",
    "        y = labels\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(X, y)\n",
    "        logging.info(\"Model training completed.\")\n",
    "\n",
    "    def predict(self, texts: list[str]) -> list[str]:\n",
    "        \"\"\"\n",
    "        Makes predictions on new text data.\n",
    "        \"\"\"\n",
    "        logging.info(\"Starting prediction.\")\n",
    "        # Preprocess new texts\n",
    "        processed_texts = [self.preprocess_text(text) for text in texts]\n",
    "\n",
    "        # Transform texts using the fitted vectorizer\n",
    "        X_new = self.vectorizer.transform(processed_texts)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(X_new).tolist()\n",
    "        logging.info(\"Prediction completed.\")\n",
    "        return predictions\n",
    "\n",
    "    def evaluate(self, texts: list[str], true_labels: list[str]) -> float:\n",
    "        \"\"\"\n",
    "        Evaluates the model's accuracy.\n",
    "        \"\"\"\n",
    "        logging.info(\"Starting model evaluation.\")\n",
    "        predictions = self.predict(texts)\n",
    "        score = accuracy_score(true_labels, predictions)\n",
    "        logging.info(f\"Model accuracy: {score:.4f}\")\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd3c1fd",
   "metadata": {},
   "source": [
    "## 3) Initialise the classifier\n",
    "Create an instance of `TextClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a4d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 13:28:15,646 - INFO - TextClassifier initialized.\n",
      "2026-02-20 13:28:15,648 - INFO - Classifier instance created.\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier()\n",
    "logging.info(\"Classifier instance created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54239e42",
   "metadata": {},
   "source": [
    "## 4) Load dataset\n",
    "Load the CSV at `data/raw/text-label.csv` and inspect a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6895501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 263 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After deploying to staging the site returns a ...</td>\n",
       "      <td>config</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Application fails to start on production becau...</td>\n",
       "      <td>config</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMTP emails are not being delivered; service l...</td>\n",
       "      <td>config</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAuth login fails with redirect URI does not m...</td>\n",
       "      <td>config</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSL handshake error in browser; certificate ch...</td>\n",
       "      <td>config</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0  After deploying to staging the site returns a ...  config\n",
       "1  Application fails to start on production becau...  config\n",
       "2  SMTP emails are not being delivered; service l...  config\n",
       "3  OAuth login fails with redirect URI does not m...  config\n",
       "4  SSL handshake error in browser; certificate ch...  config"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/raw/text-label.csv\")\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "print(f\"Loaded {len(texts)} samples\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36399f7",
   "metadata": {},
   "source": [
    "## 5) Split into train/test\n",
    "We use `train_test_split` with the same parameters as `app.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895d0af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 210 samples, Test: 53 samples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "print(f\"Train: {len(X_train)} samples, Test: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d78ceec",
   "metadata": {},
   "source": [
    "## 6) Train the model\n",
    "Call the `train` method on the classifier with the training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155da64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 13:28:15,741 - INFO - Starting model training.\n",
      "2026-02-20 13:28:15,902 - INFO - Model training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "classifier.train(X_train, y_train)\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101058a9",
   "metadata": {},
   "source": [
    "## 7) Evaluate on the test set\n",
    "Compute accuracy on the held-out test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efe44b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 13:28:15,954 - INFO - Starting model evaluation.\n",
      "2026-02-20 13:28:15,955 - INFO - Starting prediction.\n",
      "2026-02-20 13:28:15,958 - INFO - Prediction completed.\n",
      "2026-02-20 13:28:15,963 - INFO - Model accuracy: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7605728b",
   "metadata": {},
   "source": [
    "## 8) Predict on new unseen data\n",
    "Create a small list of unseen texts and call `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed5f017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 13:28:15,979 - INFO - Starting prediction.\n",
      "2026-02-20 13:28:15,982 - INFO - Prediction completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: 'This is an absolutely fantastic product, highly recommended!' -> Predicted: code\n",
      "Text 2: 'I am extremely disappointed with the quality.' -> Predicted: code\n",
      "Text 3: 'It's an average item, nothing special but not bad.' -> Predicted: config\n",
      "Text 4: 'What a great product, I will buy 2 more!' -> Predicted: code\n",
      "Text 5: 'This was a terrible investment, I regret it.' -> Predicted: code\n"
     ]
    }
   ],
   "source": [
    "new_texts_for_prediction = [\n",
    "    \"This is an absolutely fantastic product, highly recommended!\",\n",
    "    \"I am extremely disappointed with the quality.\",\n",
    "    \"It's an average item, nothing special but not bad.\",\n",
    "    \"What a great product, I will buy 2 more!\",\n",
    "    \"This was a terrible investment, I regret it.\",\n",
    "]\n",
    "predictions = classifier.predict(new_texts_for_prediction)\n",
    "for i, (text, pred) in enumerate(zip(new_texts_for_prediction, predictions)):\n",
    "    print(f\"Text {i+1}: '{text}' -> Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2d657",
   "metadata": {},
   "source": [
    "## Notebook complete\n",
    "You can run the cells in order. If you want, I can run the notebook here to capture outputs, or adjust the notebook to import the existing `src` module instead of copying the class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
